{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88263ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from matplotlib import pyplot as plt\n",
    "from baukit import PlotWidget, show\n",
    "\n",
    "class Sign(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, dict):\n",
    "            return {k: v.sign() for k, v in x.items()}\n",
    "        return x.sign()\n",
    "\n",
    "x = torch.linspace(-2, 2, 101)\n",
    "plt.title('Sign (step) nonlinearity')\n",
    "plt.plot(x, Sign()(x))\n",
    "plt.xlabel('input')\n",
    "plt.ylabel('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b213b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class McCulloughPittsNeuron(torch.nn.Module):\n",
    "    '''\n",
    "    A McCoullough-Pitts Neuron.  It computes a weighted sum of any number of inputs,\n",
    "    then it thresholds the output through a nonlinear activation step function.\n",
    "    It pulls named inputs from an input dictionary and puts output into the\n",
    "    dictionary.  That allows networks to be created by sequencing neurons and\n",
    "    connecting them by using dictionary names.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        net = McCulloughPittsNeuron(\n",
    "                weight_a = 0.5,\n",
    "                weight_b = -0.3,\n",
    "                weight_c = 2.0,\n",
    "                bias     = 1.0)\n",
    "        print(net(dict(\n",
    "                a=Tensor([1.0]),\n",
    "                b=Tensor([-1.0]),\n",
    "                c=Tensor([-1.0])))['out'])\n",
    "\n",
    "    The above creates a single neuron with three inputs a, b, and c plus some bias.\n",
    "    It is invoked by providing a dictionary of all the inputs as tensors.\n",
    "\n",
    "        net = torch.nn.Sequential(\n",
    "            McCulloughPittsNeuron(weight_a=-1.0, weight_b=1.0, output_name='d'),\n",
    "            McCulloughPittsNeuron(weight_b=1.0, weight_d=1.0, bias=1.0),\n",
    "        )\n",
    "        print(net(dict(a=Tensor([1.0]), b=Tensor([-1.0])))['out'])\n",
    "\n",
    "    The above creates and runs a network of two neurons in this configuration:\n",
    "    ```\n",
    "             a -----> +----------+\n",
    "                      | Neuron 0 | ---> d --+\n",
    "             b ---+-> +----------+          +--> +----------+\n",
    "                  |                              | Neuron 1 | ---> out\n",
    "                  +----------------------------> +----------+\n",
    "    ```\n",
    "    As the sequence is run, the dictionary grows; after the first neuron is run,\n",
    "    the dictionary contains a, b, and d.  After the second neuron is ru , the\n",
    "    final dictionary contains a, b, d, and out.\n",
    "    '''\n",
    "    def __init__(self, bias=0.0, activation=Sign, output_name='out', **kwargs):\n",
    "        '''\n",
    "        Construct a neuron by specifying any number of input weights in the arguments:\n",
    "        \n",
    "            weight_a:    The weight for the 'a' input.\n",
    "                         Each `weight_x` in the constructor adds an input named 'x'.\n",
    "            bias:        The constant bias to add to the weighted sum.\n",
    "            output_name: The output name, defaults to 'out'.\n",
    "            activation:  The nonlinearity to use; defaults to the \"Sign\" step function.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        # We use the pytorch Linear module with a one-dimenaional output\n",
    "        self.summation = torch.nn.Linear(len(kwargs), 1)\n",
    "        self.activation = None if activation is None else activation()\n",
    "        self.output_name = output_name\n",
    "        self.input_names = []\n",
    "        with torch.no_grad():\n",
    "            self.summation.bias[...] = bias\n",
    "            for k, v in kwargs.items():\n",
    "                assert k.startswith('weight_'), f'Bad argument {k}'\n",
    "                self.summation.weight[0, len(self.input_names)] = v\n",
    "                self.input_names.append(k[7:])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        The inputs should be a dictionary containing the expected input keys.\n",
    "        The results are computed.  Then the return value will be a copy of the\n",
    "        input dictionary, with the additional output tensor added.\n",
    "        '''\n",
    "        state = inputs.copy()\n",
    "        assert self.output_name not in state, f'Multiple {self.output_name}\\'s conflict'\n",
    "        x = torch.stack([inputs[v] for v in self.input_names], dim=1)\n",
    "        x = self.summation(x)[:,0]\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        state[self.output_name] = x\n",
    "        return state\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return f'input_names={self.input_names}, output_name=\\'{self.output_name}\\''\n",
    "\n",
    "def visualize_logic(nets, arg1='a', arg2='b'):\n",
    "    '''\n",
    "    Pass any number of McCoullough-Pitts neurons or neural networks with two\n",
    "    inputs named 'a' and 'b', and it will visualize all of their logic, using\n",
    "    white squares to indicate +1, black squares to indicate -1, and orange\n",
    "    squares to indicate intermediate values.\n",
    "    '''\n",
    "    grid = torch.Tensor([[\n",
    "        [-1.0, 1.0],\n",
    "        [-1.0, 1.0],\n",
    "    ], [\n",
    "        [ 1.0, 1.0],\n",
    "        [-1.0,-1.0],\n",
    "    ]])\n",
    "    a, b = grid\n",
    "    def make_viz(n):\n",
    "        if isinstance(n, list):\n",
    "            return [make_viz(net) for net in n]\n",
    "        def make_plot(fig):\n",
    "            with torch.no_grad():\n",
    "                out = n({arg1: a.view(-1), arg2: b.view(-1)})['out'].view(a.shape)\n",
    "            [ax] = fig.axes\n",
    "            ax.imshow(out, cmap='hot', extent=[-2,2,-2,2], vmin=-1, vmax=1)\n",
    "            ax.invert_yaxis()\n",
    "            ax.xaxis.tick_top()\n",
    "            ax.tick_params(length=0)\n",
    "            ax.set_xticks([-1, 1], [f'{arg1}=-1', f'{arg1}=1'])\n",
    "            ax.set_yticks([-1, 1], [f'{arg2}=-1', f'{arg2}=1'])\n",
    "        return PlotWidget(make_plot, figsize=(1.1,1.1), dpi=100, bbox_inches='tight')\n",
    "    show(show.WRAP, make_viz(nets))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_logic([\n",
    "    # First network: just one neuron.\n",
    "    McCulloughPittsNeuron(weight_a=1.0, weight_b=1.0, bias=0.0),\n",
    "    \n",
    "    # Second network: two neurons hooked together.\n",
    "    torch.nn.Sequential(\n",
    "        McCulloughPittsNeuron(weight_a=-1.0, weight_b=1.0, bias=0.0, output_name='d'),\n",
    "        McCulloughPittsNeuron(weight_b=1.0, weight_d=1.0, bias=1.0),\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c987f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_logic([\n",
    "    McCulloughPittsNeuron(weight_a=1.0, weight_b=1.0, bias=1.0),\n",
    "    McCulloughPittsNeuron(weight_a=1.0, weight_b=-1.0, bias=1.0),\n",
    "    McCulloughPittsNeuron(weight_a=-1.0, weight_b=-1.0, bias=1.0),\n",
    "    McCulloughPittsNeuron(weight_a=-1.0, weight_b=1.0, bias=1.0),\n",
    "    McCulloughPittsNeuron(weight_a=1.0, weight_b=1.0, bias=-1.0),\n",
    "    McCulloughPittsNeuron(weight_a=1.0, weight_b=-1.0, bias=-1.0),\n",
    "    McCulloughPittsNeuron(weight_a=-1.0, weight_b=-1.0, bias=-1.0),\n",
    "    McCulloughPittsNeuron(weight_a=-1.0, weight_b=1.0, bias=-1.0),\n",
    "    McCulloughPittsNeuron(weight_a=1.0, weight_b=0.0, bias=0.0),\n",
    "    McCulloughPittsNeuron(weight_a=0.0, weight_b=1.0, bias=0.0),\n",
    "    torch.nn.Sequential(\n",
    "        McCulloughPittsNeuron(weight_a=-1.0, weight_b=-1.0, bias=1.0, output_name='c'),\n",
    "        McCulloughPittsNeuron(weight_a=1.0, weight_b=1.0, bias=1.0, output_name='d'),\n",
    "        McCulloughPittsNeuron(weight_c=1.0, weight_d=1.0, bias=-1.0),\n",
    "    ),\n",
    "    torch.nn.Sequential(\n",
    "        McCulloughPittsNeuron(weight_a=-1.0, weight_b=-1.0, bias=1.0, output_name='c'),\n",
    "        McCulloughPittsNeuron(weight_a=1.0, weight_b=1.0, bias=1.0, output_name='d'),\n",
    "        McCulloughPittsNeuron(weight_c=-1.0, weight_d=-1.0, bias=1.0),\n",
    "    ),\n",
    "    McCulloughPittsNeuron(weight_a=-1.0, weight_b=0.0, bias=0.0),\n",
    "    McCulloughPittsNeuron(weight_a=0.0, weight_b=-1.0, bias=0.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b397da",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    McCulloughPittsNeuron(weight_a=-1.0, weight_b=1.0, output_name='c'),\n",
    "    McCulloughPittsNeuron(weight_b=1.0, weight_c=1.0, bias=1.0),\n",
    ")\n",
    "print(net(dict(a=Tensor([1.0]), b=Tensor([-1.0])))['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = McCulloughPittsNeuron(weight_a=0.5, weight_b=-0.3, weight_c=2.0, bias=1.0)\n",
    "print(net(dict(a=Tensor([1.0]), b=Tensor([-1.0]), c=Tensor([-1.0])))['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3020461",
   "metadata": {},
   "outputs": [],
   "source": [
    "net(dict(a=torch.tensor([1.0]).float(), b=torch.tensor([1.0]).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ffeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a788f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x = torch.linspace(-10, 10, 101)\n",
    "\n",
    "plt.plot(x, torch.sigmoid(x))\n",
    "\n",
    "plt.plot(x, (x > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d29254",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x>0).to(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
