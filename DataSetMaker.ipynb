{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465d58be",
   "metadata": {},
   "source": [
    "# Script for making coco_humans sample data set\n",
    "\n",
    "First, load up a pretrained CLIP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857fe29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import requests\n",
    "from baukit import save_image_set\n",
    "from baukit import ImageFolderSet, show, move_to\n",
    "import torchvision\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-L/14\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f6324",
   "metadata": {},
   "source": [
    "Next, load the COCO 2017 data set.  We will use the training data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_dir = '/share/data/datasets/coco/images/train2017'\n",
    "ds = ImageFolderSet(input_image_dir, transform=preprocess, identification=True)\n",
    "ds_cropped = ImageFolderSet(input_image_dir,\n",
    "                            transform=torchvision.transforms.Compose(\n",
    "                                preprocess.transforms[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8f166",
   "metadata": {},
   "source": [
    "Precompute CLIP features for a couple positive prompts and a couple negative prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52503b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_text = clip.tokenize([\"a picture of a woman or a man\", \"a professional at work\"]).to(device)\n",
    "positive_features = model.encode_text(positive_text)\n",
    "negative_text = clip.tokenize([\"a picture of some junk\", \"a cluttered mess\"]).to(device)\n",
    "negative_features = model.encode_text(negative_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff6de4",
   "metadata": {},
   "source": [
    "Demo of tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08204c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = clip.simple_tokenizer.SimpleTokenizer()\n",
    "tokenizer.decode(positive_text[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71915dcc",
   "metadata": {},
   "source": [
    "Collect top 2000 scoring images, adding positive similarities and subtracting negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18806fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from baukit import TopK, pbar\n",
    "\n",
    "stat = TopK(k=2000)\n",
    "for batch in pbar(DataLoader(ds, batch_size=100, pin_memory=True, num_workers=30)):\n",
    "    [[images, indexes]] = move_to(device, batch)\n",
    "    image_features = model.encode_image(images)\n",
    "    sim = sum(cosine_similarity(image_features, f[None], dim=1) for f in positive_features)\n",
    "    neg = sum(cosine_similarity(image_features, f[None], dim=1) for f in negative_features)\n",
    "    stat.add(sim - neg, indexes)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(show.WRAP, [[show.style(maxWidth=120), ds_cropped[i]] for i in stat.topk()[1][0:12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9220b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from baukit import WorkerPool, save_image_set\n",
    "\n",
    "os.makedirs('coco_humans', exist_ok=True)\n",
    "save_image_set(random.sample([ds_cropped[i][0] for i in stat.topk()[1]], len(stat.topk()[1])),\n",
    "               'coco_humans/image_{0}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d675e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import baukit.workerpool, baukit.imgsave\n",
    "reload(baukit.workerpool)\n",
    "reload(baukit.imgsave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baukit.workerpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a61fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
