{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This visulaization function is used for the next example\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def endpoints(w, b, scale=10):\n",
    "    if abs(w[1]) > abs(w[0]):\n",
    "        x0 = torch.tensor([-scale, scale]).to(w.device)\n",
    "        x1 = (-b - w[0] * x0) / w[1]\n",
    "    else:\n",
    "        x1 = torch.tensor([-scale, scale]).to(w.device)\n",
    "        x0 = (-b - w[1] * x1) / w[0]\n",
    "    return torch.stack([x0, x1], dim=1)\n",
    "\n",
    "def visualize_net(net, classify_target):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    grid = torch.stack([\n",
    "        torch.linspace(-2, 2, 100)[None, :].expand(100, 100),\n",
    "        torch.linspace(2, -2, 100)[:, None].expand(100, 100),\n",
    "    ])\n",
    "    x, y = grid\n",
    "    target = classify_target(x, y)\n",
    "    ax1.set_title('target')\n",
    "    ax1.imshow(target.float(), cmap='hot', extent=[-2,2,-2,2])\n",
    "    ax2.set_title('network output')\n",
    "    score = net(grid.permute(1, 2, 0).reshape(-1, 2).cuda()).softmax(1)\n",
    "    ax2.imshow(score[:,1].reshape(100, 100).detach().cpu(), cmap='hot', extent=[-2,2,-2,2])\n",
    "\n",
    "    ax3.set_title('first layer folds')\n",
    "    module = [m for m in net.modules() if isinstance(m, torch.nn.Linear)][0]\n",
    "    w = module.weight.detach().cpu()\n",
    "    b = module.bias.detach().cpu()\n",
    "    e = torch.stack([endpoints(wc, bc) for wc, bc in zip(w, b)])\n",
    "    for ep in e:\n",
    "        ax3.plot(ep[:,0], ep[:,1], '#00ff00', linewidth=0.75, alpha=0.33)\n",
    "    ax3.set_ylim(-2, 2)\n",
    "    ax3.set_xlim(-2, 2)\n",
    "    ax3.set_aspect(1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ec6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "from torch.nn.functional import cross_entropy, mse_loss\n",
    "\n",
    "def classify_target(x, y):\n",
    "    return (y > (x * 3).sin()).long()\n",
    "def classify_target(x, y):\n",
    "    return (y.floor() + x.floor()).long() % 2\n",
    "\n",
    "mlp = torch.nn.Sequential(OrderedDict([\n",
    "    ('layer1', Sequential(Linear(2, 100), ReLU())),\n",
    "    ('layer2', Sequential(Linear(100, 2, bias=False)))\n",
    "]))\n",
    "mlp.cuda()\n",
    "#optimizer = SGD(mlp.parameters(), lr=0.01, momentum=0.95)\n",
    "optimizer = Adam(mlp.layer2.parameters(), lr=0.01)\n",
    "for iteration in range(1024 * 8):\n",
    "    in_batch = torch.randn(10000, 2, device='cuda')\n",
    "    target_batch = classify_target(in_batch[:,0], in_batch[:,1])\n",
    "    out_batch = mlp(in_batch)\n",
    "    loss = mse_loss(out_batch, torch.eye(2)[target_batch].cuda())\n",
    "    loss += (mlp.layer2[0].weight ** 2).sum() * 1e-6\n",
    "    #loss = cross_entropy(out_batch, target_batch)\n",
    "    if iteration > 0:\n",
    "        mlp.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if iteration == 2 ** iteration.bit_length() - 1:\n",
    "        pred_batch = out_batch.max(1)[1]\n",
    "        accuracy = (pred_batch == target_batch).float().sum() / len(in_batch)\n",
    "        print(f'Iteration {iteration} accuracy: {accuracy}')\n",
    "        visualize_net(mlp, classify_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = torch.nn.Sequential(OrderedDict([\n",
    "    ('layer1', Sequential(Linear(2, 100), ReLU())),\n",
    "    ('layer2', Sequential(Linear(100, 2, bias=False)))\n",
    "]))\n",
    "mlp.cuda()\n",
    "in_batch = torch.randn(100000, 2, device='cuda')\n",
    "target_batch = classify_target(in_batch[:,0], in_batch[:,1])\n",
    "target_batch = torch.eye(2)[target_batch].cuda()\n",
    "with torch.no_grad():\n",
    "    hidden_batch = mlp.layer1(in_batch)\n",
    "    inv = torch.linalg.pinv(hidden_batch.t().double()).float()\n",
    "    mlp.layer2[0].weight[...] = target_batch.t() @ inv\n",
    "visualize_net(mlp, classify_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = torch.nn.Sequential(OrderedDict([\n",
    "    ('layer1', Sequential(Linear(2, 200), ReLU())),\n",
    "    ('layer2', Sequential(Linear(200, 2, bias=False)))\n",
    "])).cuda()\n",
    "optimizer = Adam(mlp.parameters(), lr=0.01)\n",
    "for iteration in range(1024 * 8):\n",
    "    in_batch = torch.randn(10000, 2, device='cuda')\n",
    "    target_batch = classify_target(in_batch[:,0], in_batch[:,1])\n",
    "    out_batch = mlp(in_batch)\n",
    "    #loss = mse_loss(out_batch, torch.eye(2)[target_batch].cuda())\n",
    "    loss = cross_entropy(out_batch, target_batch)\n",
    "    #loss += (mlp.layer2[0].weight ** 2).sum() * 1e-6\n",
    "    if iteration > 0:\n",
    "        mlp.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if iteration == 2 ** iteration.bit_length() - 1:\n",
    "        pred_batch = out_batch.max(1)[1]\n",
    "        accuracy = (pred_batch == target_batch).float().sum() / len(in_batch)\n",
    "        print(f'Iteration {iteration} accuracy: {accuracy}')\n",
    "        visualize_net(mlp, classify_target)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
