{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# This function loads several neural networks to use together.\n",
    "# The individual networks and preprocessors loaded are listed in this file:\n",
    "# https://huggingface.co/CompVis/stable-diffusion-v1-4/blob/main/model_index.json\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "    revision=\"fp16\",\n",
    "    torch_dtype=torch.float16, \n",
    "    use_auth_token=True\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f405f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(vars(pipe).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d7edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, a in vars(pipe).items():\n",
    "    if isinstance(a, torch.nn.Module):\n",
    "        print(f'{type(a).__name__} \"{n}\" has:')\n",
    "        print(f'{sum(p.numel() for p in a.parameters())} parameters in '\n",
    "              f'{len(list(a.parameters()))} tensors in '\n",
    "              f'{len(list(p.modules() for p in a.modules()))} modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "print(count_parameters(pipe.text_encoder))\n",
    "print(count_parameters(pipe.unet))\n",
    "print(count_parameters(pipe.vae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae260f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import show, renormalize, pbar\n",
    "from torch import autocast\n",
    "import numpy\n",
    "\n",
    "prompt = \"Photo of Chewbacca and Angela Merkel solving a Rubik's cube on Boston Common\"\n",
    "seed = 2\n",
    "\n",
    "# Stable Diffusion inference devised by Robin Rombach et al. (CVPR 2022, https://arxiv.org/abs/2112.10752)\n",
    "# Derived from the Huggingface Stable Diffusion pipeline by Suraj Patil and others\n",
    "# https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L16-L171\n",
    "with autocast(device), torch.no_grad():\n",
    "    text_tokens = pipe.tokenizer([\"\", prompt], padding=\"max_length\", return_tensors=\"pt\")['input_ids']\n",
    "    text_vectors = pipe.text_encoder(text_tokens.to(device))[0]\n",
    "    image_vectors = torch.from_numpy(numpy.random.RandomState(seed).randn(1, 4, 64, 64)).float().to(device)\n",
    "    \n",
    "    # The scheduler uses a linear multistep (PLMS) method proposed by Katherine Crowson\n",
    "    # https://github.com/crowsonkb/k-diffusion\n",
    "    scheduler = pipe.scheduler\n",
    "    scheduler.set_timesteps(33)\n",
    "    latent_scale = 0.18215\n",
    "    guidance_strength = 5.0\n",
    "    intermediates = []\n",
    "    for t in pbar(scheduler.timesteps):\n",
    "        intermediates.extend(renormalize.as_image(pipe.vae.decode(image_vectors / latent_scale)))\n",
    "        # Pass two copies into the network, one to process with \"\" and the other with prompt.\n",
    "        image_vector_input = torch.cat([image_vectors] * 2)\n",
    "        # pipe.unet is a neural network inputs image_vector_inputs and text_vectors and outputs some updates\n",
    "        update = pipe.unet(image_vector_input, t, text_vectors)[\"sample\"]\n",
    "        # Classifier-free guidance: see Jonathan Ho and Tim Salimans\n",
    "        # (Neurips 2021 Workshop, https://arxiv.org/abs/2207.12598)\n",
    "        strong_guidance = update[0] + guidance_strength * (update[1] - update[0])\n",
    "        image_vectors = scheduler.step(strong_guidance, t, image_vectors)[\"prev_sample\"]\n",
    "\n",
    "    # pipe.vae is a neural network\n",
    "    rgb_vectors = pipe.vae.decode(image_vectors / latent_scale)\n",
    "    intermediates.extend(renormalize.as_image(rgb_vectors))\n",
    "    show(show.WRAP, [[show.style(width=144), im] for im in intermediates])\n",
    "    print('Text tokens are', tokens.shape, tokens.dtype)\n",
    "    print('Text vectors are', text_vectors.shape, text_vectors.dtype)\n",
    "    print('Image vectors are', image_vectors.shape, image_vectors.dtype)\n",
    "    print('RGB vectors are', rgb_vectors.shape, rgb_vectors.dtype)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b27a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from baukit import ImageFolderSet\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "\n",
    "if not os.path.isdir('coco_humans'):\n",
    "    download_and_extract_archive('https://cs7150.baulab.info/2022-Fall/data/coco_humans.zip', 'coco_humans')\n",
    "\n",
    "images = ImageFolderSet('coco_humans', transform=Compose([\n",
    "    ToTensor(),\n",
    "    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "]))\n",
    "for image in images:\n",
    "    safety_cheker_input = pipe.feature_extractor(image, return_tensors=\"pt\").to(self.device)\n",
    "    _, has_nsfw_concept = pipe.safety_checker(images=image, clip_input=safety_cheker_input.pixel_values)\n",
    "    if has_nsfw_concept:\n",
    "        show(image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
