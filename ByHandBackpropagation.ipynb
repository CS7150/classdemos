{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de32f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class ComputationNode:\n",
    "    def __init__(self, *input_nodes, name=None):\n",
    "        '''\n",
    "        A computation graph is an acyclic graph of nodes, each representing\n",
    "        a value that is computed from its child (predecessor) input_nodes.\n",
    "        In our implementation, you must give the input nodes at construction\n",
    "        time, and unlike pytorch we do not compute the result right away.\n",
    "        We also do not compute the gradient yet. Those are your jobs.\n",
    "        '''\n",
    "        self.name = name\n",
    "        self.input_nodes = input_nodes\n",
    "        self.result = None\n",
    "        self.gradient = 0.0\n",
    "    def input(self, i):\n",
    "        '''\n",
    "        After the results are already computed in an input node, this\n",
    "        method gives you the result of the ith input.\n",
    "        '''\n",
    "        return self.input_nodes[i].result\n",
    "    def forward(self):\n",
    "        '''\n",
    "        The job of forward is to do the computation, and fill in self.result.\n",
    "        '''\n",
    "        assert 'Implementation needed' # Subclasses must override\n",
    "        self.result = function_of(self.input(0)) # Example\n",
    "    def backward(self, upstream_gradient):\n",
    "        '''\n",
    "        The job of backward is to do one step of backprop, which has two steps:\n",
    "        1. The current node's own gradient must be updated based on the upstream gradient.\n",
    "        2. A downstream gradient is computed for each of the current node's inputs.\n",
    "        This function should return a list of downstream gradients, one for\n",
    "        each input.\n",
    "        '''\n",
    "        assert 'Implementation needed' # Subclasses must override\n",
    "        self.gradient += upstream_gradient # Example\n",
    "        return [compute_downstream_gradient(upstream_gradient, self.result, inp.result) for inp in self.input_nodes]\n",
    "    def leaves(self, result=None):\n",
    "        '''\n",
    "        Fills in and returns a dictionary of all the leaf nodes in the tree under the current node.\n",
    "        '''\n",
    "        if result is None: result = {}\n",
    "        if self.name is not None:\n",
    "            assert self.name not in result or result[self.name] is self, f'Different nodes named {self.name}'\n",
    "            result[self.name] = self\n",
    "        for node in self.input_nodes:\n",
    "            node.leaves(result)\n",
    "        return result\n",
    "    def __repr__(self):\n",
    "        '''Print out the tree so you can see the form of the graph.'''\n",
    "        name = type(self).__name__ + (' ' + self.name if self.name else '')\n",
    "        our_repr = f'{name} result={self.result} gradient={self.gradient}'\n",
    "        tree_repr = '\\n'.join([our_repr] + list(node.__repr__() for node in self.input_nodes))\n",
    "        return '\\n  '.join(tree_repr.split('\\n'))\n",
    "    \n",
    "    # For convenience, we automatically construct computation nodes based\n",
    "    # some method and infix operators.  You can add more.  Pytorch does this too.\n",
    "    def exp(self):\n",
    "        return Exp(self)\n",
    "    def __neg__(self):\n",
    "        return Negate(self)\n",
    "    def __pow__(self, int_power):\n",
    "        return IntPow(self, int_power) # Optinal: you could make an IntPow class\n",
    "    def __add__(self, other):\n",
    "        return Sum(self, other) # You should make a Sum class\n",
    "    def __mul__(self, other):\n",
    "        return Product(self, other) # You should make a Product class\n",
    "\n",
    "class Leaf(ComputationNode):\n",
    "    def __init__(self, **kwargs):\n",
    "        assert len(kwargs) == 1, 'Leaf must specify one unique name=number'\n",
    "        [(name, value)] = kwargs.items()\n",
    "        super().__init__(name=name)\n",
    "        self.value = value\n",
    "    def forward(self):\n",
    "        self.result = self.value\n",
    "    def backward(self, upstream_gradient):\n",
    "        self.gradient += upstream_gradient\n",
    "        return [] # no downstream gradient\n",
    "\n",
    "class Exp(ComputationNode):\n",
    "    def forward(self):\n",
    "        x = self.input(0)\n",
    "        self.result = x.exp() if callable(getattr(x, 'exp', None)) else math.exp(x)\n",
    "    def backward(self, upstream_gradient):\n",
    "        self.gradient += upstream_gradient\n",
    "        local_gradient = self.result\n",
    "        return [local_gradient * upstream_gradient]\n",
    "\n",
    "class Negate(ComputationNode):\n",
    "    def forward(self):\n",
    "        self.result = -self.input(0)\n",
    "    def backward(self, upstream_gradient):\n",
    "        self.gradient += upstream_gradient\n",
    "        # return downstream gradient\n",
    "        return [-upstream_gradient]\n",
    "    \n",
    "class Mean(ComputationNode):\n",
    "    def forward(self):\n",
    "        self.result = (self.input(0) + self.input(1)) / 2\n",
    "    def backward(self, upstream_gradient):\n",
    "        self.gradient += upstream_gradient\n",
    "        # return downstream gradient\n",
    "        return [upstream_gradient / 2, upstream_gradient / 2]\n",
    "\n",
    "def forward_algorithm(tree):\n",
    "    # TODO: you fill in the code here\n",
    "    return tree\n",
    "\n",
    "def backward_algorithm(tree, upstream_gradient=1.0):\n",
    "    # TODO: you fill in the code here\n",
    "    return tree\n",
    "\n",
    "def zero_gradient(tree):\n",
    "    # TODO: you fill in the code here\n",
    "    return tree\n",
    "\n",
    "\n",
    "x = Leaf(x=0.5)\n",
    "sinh_x = Mean(Exp(x), -Exp(-x))\n",
    "cosh_x = Mean(Exp(x), Exp(-x))\n",
    "print('sinh_x tree:', sinh_x)\n",
    "print('sinh_x forward result:', forward_algorithm(sinh_x).result)\n",
    "print('sinh_x backward leaves:', backward_algorithm(sinh_x).leaves())\n",
    "print('cosh_x tree:', cosh_x)\n",
    "print('cosh_x forward result:', forward_algorithm(cosh_x).result)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_algorithm(tree):\n",
    "    for node in tree.input_nodes:\n",
    "        forward_algorithm(node)\n",
    "    tree.forward()\n",
    "    return tree\n",
    "\n",
    "def backward_algorithm(tree, upstream_gradient=1.0):\n",
    "    downstream_gradient = tree.backward(upstream_gradient) \n",
    "    for i, node in enumerate(tree.input_nodes):\n",
    "        backward_algorithm(node, downstream_gradient[i])\n",
    "    return tree\n",
    "\n",
    "def zero_gradient(tree):\n",
    "    for node in tree.input_nodes:\n",
    "        zero_gradient(node)\n",
    "    tree.gradient = 0.0\n",
    "    return tree\n",
    "\n",
    "x = Leaf(x=0.5)\n",
    "sinh_x = Mean(Exp(x), -Exp(-x))\n",
    "cosh_x = Mean(Exp(x), Exp(-x))\n",
    "print('sinh_x tree:', sinh_x)\n",
    "print('sinh_x forward result:', forward_algorithm(sinh_x).result)\n",
    "print('sinh_x backward leaves:', backward_algorithm(sinh_x).leaves())\n",
    "zero_gradient(cosh_x)\n",
    "print('cosh_x tree:', cosh_x)\n",
    "print('cosh_x forward result:', forward_algorithm(cosh_x).result)\n",
    "print('cosh_x backward leaves:', backward_algorithm(cosh_x).leaves())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntPow(ComputationNode):\n",
    "    def __init__(self, int_power):\n",
    "        super().__init__()\n",
    "        self.int_power = int_power\n",
    "    def forward(self):\n",
    "        self.result = self.input(0) ** self.int_power\n",
    "    def backward(self, upstream_gradient):\n",
    "        self.gradient += upstream_gradient\n",
    "        # return downstream gradient\n",
    "        return [upstream_gradient * self.int_power * (self.input(0) ** (self.int_power - 1))]\n",
    "    \n",
    "class Sum(ComputationNode):\n",
    "    def forward(self):\n",
    "        self.result = self.inputs()[0] + self.inputs()[1]\n",
    "    def backward(self, upstream_gradient):\n",
    "        self.gradient += upstream_gradient\n",
    "        # return downstream gradient\n",
    "        return [upstream_gradient, upstream_gradient]\n",
    "\n",
    "class Product(ComputationNode):\n",
    "    def forward(self):\n",
    "        self.result = self.inputs()[0] * self.inputs()[1]\n",
    "    def backward(self, upstream_gradient):\n",
    "        self.gradient += upstream_gradient\n",
    "        inputs = self.inputs()\n",
    "        # return downstream gradient\n",
    "        return [inputs[1] * upstream_gradient, inputs[0] * upstream_gradient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_algorithm(sinh_x)\n",
    "sinh_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e140399",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_algorithm(out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_algorithm(out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_algorithm(out):\n",
    "    out.backward()\n",
    "    for inp in out.input_nodes():\n",
    "        backprop_algorithm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
