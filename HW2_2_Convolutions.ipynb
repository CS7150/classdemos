{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toeplitz Convolutions in 1D and 2D (with PyTorch and `im2col`)\n",
    "\n",
    "In this notebook, we’ll explore:\n",
    "1. **1D convolution** as a **Toeplitz** matrix.\n",
    "2. **Translation equivariance** in 1D.\n",
    "3. **2D convolution** as a **block Toeplitz** matrix (and how `im2col` reveals this structure).\n",
    "4. How to replicate a 2D convolution in PyTorch using a manually constructed linear (fully-connected) transform with repeated weights.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 1D Toeplitz Convolution\n",
    "\n",
    "### 1.1 Toeplitz Matrix (LaTeX Explanation)\n",
    "\n",
    "A **Toeplitz matrix** is one in which each descending diagonal from left to right is constant. For **1D convolution** with a kernel \\(w\\) of length \\(K\\), and an input of length \\(N\\), the \"valid\" convolution output has length \\(N-K+1\\). Denote these as:\n",
    "\\[\n",
    "x = [x_0, x_1, x_2, \\dots, x_{N-1}]^T,\\quad\n",
    "w = [w_0, w_1, \\dots, w_{K-1}],\\quad\n",
    "y = [y_0, y_1, \\dots, y_{N-K}]^T.\n",
    "\\]\n",
    "\n",
    "The 1D convolution is:\n",
    "\\[\n",
    "y[n] = \\sum_{k=0}^{K-1} w_k \\cdot x_{n+k},\\quad n = 0,1,\\dots, N-K.\n",
    "\\]\n",
    "We can encode this in a matrix multiplication:\n",
    "\\[\n",
    "y = T\\,x,\n",
    "\\]\n",
    "where \\(T\\) is a \\((N-K+1) \\times N\\) **Toeplitz** matrix of the form:\n",
    "\\[\n",
    "T = \\begin{bmatrix}\n",
    "w_0 & w_1 & w_2 & \\dots & w_{K-1} & 0      & 0 & \\dots \\\\\n",
    "0   & w_0 & w_1 & \\dots & w_{K-2} & w_{K-1} & 0 & \\dots \\\\\n",
    "\\vdots &   &  & \\ddots &   &  &  &  \\\\\n",
    "0 & 0 & 0 & \\dots & w_0 & w_1 & \\dots & w_{K-1}\n",
    "\\end{bmatrix}.\n",
    "\\]\n",
    "All rows are **shifted** copies of the same kernel, implying **weight sharing**. A **generic** \\((N-K+1) \\times N\\) matrix would have \\((N-K+1) \\times N\\) degrees of freedom, but Toeplitz structure means we only have **\\(K\\) free parameters**.\n",
    "\n",
    "### 1.2 Example in PyTorch\n",
    "We’ll do:\n",
    "- An input of length 8, mostly zeros at edges.\n",
    "- A 3-tap kernel that we set **manually** in a PyTorch `Conv1d` (with no bias).\n",
    "- Demonstrate the convolution and also show **equivariance** by shifting the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# We'll do a 1D input of length 8, zeros on edges\n",
    "x_1d = torch.tensor([ [ [0., 1., 2., 3., 4., 5., 0., 0.] ] ])  # shape (1,1,8)\n",
    "print(\"x_1d:\", x_1d)\n",
    "\n",
    "# Create a Conv1d with kernel_size=3, out_channels=1, no bias.\n",
    "conv1d_layer = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, bias=False)\n",
    "\n",
    "# Manually set the kernel to [1,2,1], for example.\n",
    "with torch.no_grad():\n",
    "    conv1d_layer.weight.zero_()\n",
    "    conv1d_layer.weight[0,0,0] = 1.0\n",
    "    conv1d_layer.weight[0,0,1] = 2.0\n",
    "    conv1d_layer.weight[0,0,2] = 1.0\n",
    "\n",
    "# Forward pass\n",
    "y_1d_conv = conv1d_layer(x_1d)\n",
    "print(\"Conv1D output shape:\", y_1d_conv.shape)\n",
    "print(\"Conv1D output:\", y_1d_conv)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Translation Equivariance Demo\n",
    "A core property of convolution is **translation equivariance** in the interior region. Let’s shift our input by 1 and see how the output changes.\n",
    "\n",
    "> **Note**: Because we do \"valid\" convolution, the edges get trimmed, so perfect equivariance only holds for shifts that keep the kernel fully within the signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Shift input by 1: [0,0,1,2,3,4,5,0]\n",
    "x_1d_shifted = torch.tensor([ [ [0., 0., 1., 2., 3., 4., 5., 0.] ] ])\n",
    "y_1d_shifted = conv1d_layer(x_1d_shifted)\n",
    "\n",
    "print(\"Shifted input:\", x_1d_shifted)\n",
    "print(\"Output of conv1d on shifted:\", y_1d_shifted)\n",
    "\n",
    "print(\"\\nCompare with original output:\", y_1d_conv)\n",
    "print(\"Difference (shifted - original):\", y_1d_shifted - y_1d_conv)\n",
    "print(\"\\nObservation: The middle entries may be shifted. The edges differ.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for the interior part of the signal, the outputs shift as well, but the edges are truncated differently, hence partial **equivariance**.\n",
    "\n",
    "---\n",
    "# Part 2: 2D Convolution via Block-Toeplitz Matrices\n",
    "\n",
    "In 2D, the equivalent **Toeplitz** concept generalizes to a **block-Toeplitz** matrix. If your kernel is \\(R\\times S\\), and the input image is \\(H\\times W\\), then the valid convolution output is \\((H - R + 1) \\times (W - S + 1)\\). If you **flatten** the input image (length \\(H\\times W\\)) and flatten the output (length \\((H - R + 1)(W - S + 1)\\)), you can create a big matrix \\(T\\) of size \\((H - R + 1)(W - S + 1) \\times (H\\times W)\\). Each row in that matrix picks out **one** \\(R\\times S\\) patch from the image.\n",
    "\n",
    "### 2.1 The `im2col` Trick\n",
    "\n",
    "A common way to see the block-Toeplitz structure is via **`im2col`**:\n",
    "1. For each valid top-left position \\((i,j)\\) in the image, extract the \\(R\\times S\\) patch, **flatten** it into a column.\n",
    "2. Stack all these columns side-by-side into a **big matrix** \\(X_{\\text{col}}\\). The shape becomes \\((R\\times S) \\times (\\text{number of patches})\\).\n",
    "3. **Flatten** the kernel as well, making it a row vector of length \\(R\\times S\\).\n",
    "4. Multiply: \\(\\text{(kernel row vector)} \\times X_{\\text{col}} = \\text{flattened convolution result}\\).\n",
    "\n",
    "Hence, `im2col` + matrix multiplication is mathematically the same as building a single giant **block-Toeplitz** matrix. However, frameworks prefer `im2col` because it can be combined with efficient matrix multiply routines.\n",
    "\n",
    "\\[\n",
    "\\underbrace{\\text{vec}(Y)}_{(H-R+1)(W-S+1)} = \n",
    "\\underbrace{\\Bigl[\\text{blocks of flattened patches}\\Bigr]}_{\\text{im2col: }(R\\times S) \\times (H-R+1)(W-S+1)} \n",
    "\\,\\times\\, \n",
    "\\underbrace{\\text{vec}(K)}_{(R\\times S)},\n",
    "\\]\n",
    "which is the same as a **(block) Toeplitz** matrix multiplication if you unroll everything at once.\n",
    "\n",
    "### 2.2 Example with a Binary Input Image\n",
    "Let’s create a 5×5 binary image, define a 3×3 kernel, and compare:\n",
    "1. **PyTorch** 2D convolution\n",
    "2. A fully connected (`Linear`) layer that we fill with the **block-Toeplitz** pattern.\n",
    "3. Confirm they match, then **visualize** both outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a 5x5 binary image.\n",
    "# We'll put some pattern of 1's.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_2d = torch.tensor([\n",
    "    [0, 1, 1, 0, 0],\n",
    "    [1, 1, 0, 1, 0],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 0, 1, 1]\n",
    "], dtype=torch.float)\n",
    "\n",
    "print(\"Input image (5x5):\")\n",
    "print(image_2d)\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(image_2d, cmap='binary')\n",
    "plt.title(\"Input Image\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Reshape for Conv2d: (batch=1, channel=1, H=5, W=5)\n",
    "x_2d = image_2d.unsqueeze(0).unsqueeze(0)\n",
    "print(\"x_2d shape:\", x_2d.shape)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll define a **3×3** kernel in a `Conv2d` layer. For a 5×5 input, the valid 2D convolution output is **3×3** (height=3, width=3)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "conv2d_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, bias=False)\n",
    "\n",
    "# Manually define a 3x3 kernel. E.g.:\n",
    "#   1  1  0\n",
    "#   0 -1 -1\n",
    "#   1  0  1\n",
    "with torch.no_grad():\n",
    "    conv2d_layer.weight.zero_()\n",
    "    conv2d_layer.weight[0,0,0,0] = 1.0\n",
    "    conv2d_layer.weight[0,0,0,1] = 1.0\n",
    "    conv2d_layer.weight[0,0,1,1] = -1.0\n",
    "    conv2d_layer.weight[0,0,1,2] = -1.0\n",
    "    conv2d_layer.weight[0,0,2,0] = 1.0\n",
    "    conv2d_layer.weight[0,0,2,2] = 1.0\n",
    "\n",
    "print(\"Kernel (3x3):\")\n",
    "print(conv2d_layer.weight)\n",
    "\n",
    "y_2d_conv = conv2d_layer(x_2d)\n",
    "print(\"\\nConvolution output shape:\", y_2d_conv.shape)  # (1,1,3,3)\n",
    "print(y_2d_conv)\n",
    "\n",
    "# Let's visualize the 3x3 output\n",
    "out_image_2d = y_2d_conv[0,0,:,:].detach()\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(out_image_2d, cmap='viridis')\n",
    "plt.title(\"PyTorch Conv2d Output\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Manual Block-Toeplitz via a `Linear` Layer\n",
    "\n",
    "If we flatten the 5×5 image (25 elements) and flatten the 3×3 output (9 elements), then a fully connected layer from 25 to 9 can replicate the same operation if we fill it in a **block-Toeplitz** pattern:\n",
    "- Each row (in the 9) picks out a certain 3×3 patch from the 25.\n",
    "- The kernel’s 9 coefficients get placed in the right positions in that row.\n",
    "\n",
    "> So, `Linear(in_features=25, out_features=9, bias=False)` initially has `25×9=225` parameters. We only want **9** unique parameters repeated in positions that correspond to the same kernel value.\n",
    "\n",
    "**Exercise**: We’ll create the layer, zero it, and fill it. (The code below does the fill, but you can have students fill it themselves as an exercise.**)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fc2d = nn.Linear(in_features=25, out_features=9, bias=False)\n",
    "with torch.no_grad():\n",
    "    fc2d.weight.zero_()\n",
    "\n",
    "print(\"Shape of fc2d weight:\", fc2d.weight.shape)  # (9,25)\n",
    "print(\"Before fill:\")\n",
    "print(fc2d.weight)\n",
    "\n",
    "def fill_block_toeplitz(fc_layer, kernel_3x3):\n",
    "    \"\"\"\n",
    "    fc_layer: nn.Linear(25->9)\n",
    "    kernel_3x3: shape (3,3)\n",
    "    We'll place each kernel entry into the correct spots for the block-Toeplitz layout.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        out_idx = 0\n",
    "        for out_row in range(3):\n",
    "            for out_col in range(3):\n",
    "                # Flattened output index (0..8)\n",
    "                out_idx = out_row*3 + out_col\n",
    "                # For each kernel cell\n",
    "                for kr in range(3):\n",
    "                    for kc in range(3):\n",
    "                        val = kernel_3x3[kr,kc].item()\n",
    "                        in_r = out_row + kr\n",
    "                        in_c = out_col + kc\n",
    "                        in_idx = in_r*5 + in_c  # flatten (in_r, in_c) in a 5x5\n",
    "                        fc_layer.weight[out_idx, in_idx] = val\n",
    "\n",
    "# Fill the fc2d layer with the same kernel\n",
    "fill_block_toeplitz(fc2d, conv2d_layer.weight[0,0,:,:])\n",
    "\n",
    "print(\"\\nAfter fill:\")\n",
    "print(fc2d.weight)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's **flatten** the input image (25,) and multiply, then reshape to (3×3) and compare.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x_2d_flat = x_2d.view(1, 25)  # shape (batch=1, 25)\n",
    "y_fc2d = fc2d(x_2d_flat)      # shape (1,9)\n",
    "y_fc2d_img = y_fc2d.view(3,3)\n",
    "\n",
    "print(\"fc2d output (3x3):\\n\", y_fc2d_img)\n",
    "\n",
    "# Compare with y_2d_conv\n",
    "print(\"\\nPyTorch conv2d output (3x3):\\n\", y_2d_conv[0,0,:,:])\n",
    "\n",
    "diff = y_fc2d_img - y_2d_conv[0,0,:,:]\n",
    "print(\"\\nDifference:\", diff)\n",
    "\n",
    "# Visualize the fc2d result\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(y_2d_conv[0,0,:,:].detach(), cmap='viridis')\n",
    "plt.title(\"Conv2D Output\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(y_fc2d_img.detach(), cmap='viridis')\n",
    "plt.title(\"Linear Block-Toeplitz Output\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see that the difference is close to zero (floating-point). The images from both methods match, confirming that we have built a **block-Toeplitz** equivalent.\n",
    "\n",
    "## 2.4 Comments on Equivariance\n",
    "Just like in 1D, a 2D convolution is **shift-equivariant** in the interior region. With valid convolution and boundary trimming, shifting large amounts will break the perfect alignment. In practice, **padding** is often introduced in neural networks so that the image boundaries are handled differently, making the network more shift-invariant in the full field of view.\n",
    "\n",
    "---\n",
    "# Summary\n",
    "\n",
    "1. **1D**: Convolution with a kernel of size \\(K\\) can be encoded as a \\((N-K+1) \\times N\\) Toeplitz matrix. We illustrated it in PyTorch and saw partial **translation equivariance**.\n",
    "2. **2D**: The same concept generalizes to a big **block-Toeplitz** matrix with repeated entries. We typically prefer the `im2col` approach to implement or explain this.\n",
    "3. **Weight Sharing**: A fully connected layer from 25 inputs to 9 outputs has 225 parameters, but a 3×3 kernel has only **9** unique parameters. This massive reduction is crucial in CNNs and also yields **shift equivariance** in the interior.\n",
   ]
  }
 ],
 "metadata": {
  "name": "Toeplitz_Convolution_im2col",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

